{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Modelado y Evaluaci√≥n\n",
    "## HabitAlpes - Predicci√≥n de Precios de Apartamentos\n",
    "\n",
    "**Objetivos**:\n",
    "- Desarrollo del modelo de ML (20% de la calificaci√≥n)\n",
    "- Evaluaci√≥n cuantitativa (20% de la calificaci√≥n)\n",
    "\n",
    "**Temas a cubrir**:\n",
    "- Preprocesamiento de datos\n",
    "- Divisi√≥n de datos (train/test/validation)\n",
    "- Ingenier√≠a de caracter√≠sticas\n",
    "- Entrenamiento de m√∫ltiples modelos:\n",
    "  - Regresi√≥n Lineal\n",
    "  - Regresi√≥n Ridge\n",
    "  - Random Forest\n",
    "  - Gradient Boosting\n",
    "  - XGBoost\n",
    "  - LightGBM\n",
    "- Comparaci√≥n de modelos\n",
    "- Evaluaci√≥n con m√©tricas (MAE, RMSE, R¬≤, MAPE)\n",
    "- Selecci√≥n del mejor modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuraci√≥n Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librer√≠as necesarias\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Image, Markdown\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# XGBoost y LightGBM\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    print(\"‚úì XGBoost disponible\")\n",
    "except ImportError:\n",
    "    print(\"‚ö† XGBoost no est√° instalado\")\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    print(\"‚úì LightGBM disponible\")\n",
    "except ImportError:\n",
    "    print(\"‚ö† LightGBM no est√° instalado\")\n",
    "\n",
    "# Importar funciones de utilidad\n",
    "from utils import (\n",
    "    cargar_datos,\n",
    "    imprimir_encabezado,\n",
    "    formatear_cop,\n",
    "    imprimir_metricas_modelo\n",
    ")\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"\\n‚úì Librer√≠as cargadas exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carga de Datos\n",
    "\n",
    "Cargaremos el dataset y realizaremos un preprocesamiento b√°sico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset\n",
    "df = cargar_datos()\n",
    "\n",
    "print(f\"\\nForma del dataset: {df.shape}\")\n",
    "print(f\"N√∫mero de registros: {df.shape[0]:,}\")\n",
    "print(f\"N√∫mero de caracter√≠sticas: {df.shape[1]:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocesamiento de Datos\n",
    "\n",
    "Realizaremos limpieza y preparaci√≥n de los datos para el modelado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar valores faltantes en la variable objetivo\n",
    "df_clean = df.dropna(subset=['precio_venta']).copy()\n",
    "\n",
    "print(f\"Registros despu√©s de eliminar NaN en precio_venta: {len(df_clean):,}\")\n",
    "print(f\"Registros eliminados: {len(df) - len(df_clean):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar valores at√≠picos extremos en precio (opcional, basado en IQR)\n",
    "Q1 = df_clean['precio_venta'].quantile(0.25)\n",
    "Q3 = df_clean['precio_venta'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 3 * IQR\n",
    "upper_bound = Q3 + 3 * IQR\n",
    "\n",
    "df_clean = df_clean[\n",
    "    (df_clean['precio_venta'] >= lower_bound) & \n",
    "    (df_clean['precio_venta'] <= upper_bound)\n",
    "]\n",
    "\n",
    "print(f\"\\nRegistros despu√©s de eliminar outliers extremos: {len(df_clean):,}\")\n",
    "print(f\"Rango de precios: {formatear_cop(df_clean['precio_venta'].min())} - {formatear_cop(df_clean['precio_venta'].max())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Selecci√≥n de Caracter√≠sticas\n",
    "\n",
    "Seleccionaremos las caracter√≠sticas m√°s relevantes para el modelado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caracter√≠sticas num√©ricas principales\n",
    "caracteristicas_numericas = [\n",
    "    'area', 'habitaciones', 'banos', 'parqueaderos', 'piso', 'antiguedad'\n",
    "]\n",
    "\n",
    "# Caracter√≠sticas de amenidades (binarias)\n",
    "amenidades = [\n",
    "    'piscina', 'gimnasio', 'ascensor', 'vigilancia', 'zona_social',\n",
    "    'salon_comunal', 'parqueadero_visitantes', 'zonas_verdes'\n",
    "]\n",
    "\n",
    "# Caracter√≠sticas categ√≥ricas\n",
    "caracteristicas_categoricas = ['localidad', 'estrato']\n",
    "\n",
    "# Filtrar solo las que existen en el dataset\n",
    "caracteristicas_numericas = [c for c in caracteristicas_numericas if c in df_clean.columns]\n",
    "amenidades = [c for c in amenidades if c in df_clean.columns]\n",
    "caracteristicas_categoricas = [c for c in caracteristicas_categoricas if c in df_clean.columns]\n",
    "\n",
    "print(\"Caracter√≠sticas seleccionadas:\")\n",
    "print(f\"  Num√©ricas: {len(caracteristicas_numericas)}\")\n",
    "print(f\"  Amenidades: {len(amenidades)}\")\n",
    "print(f\"  Categ√≥ricas: {len(caracteristicas_categoricas)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ingenier√≠a de Caracter√≠sticas\n",
    "\n",
    "Crearemos nuevas caracter√≠sticas derivadas para mejorar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear caracter√≠sticas derivadas\n",
    "df_fe = df_clean.copy()\n",
    "\n",
    "# Precio por metro cuadrado (para an√°lisis, no como feature)\n",
    "if 'area' in df_fe.columns:\n",
    "    df_fe['precio_m2'] = df_fe['precio_venta'] / df_fe['area']\n",
    "    \n",
    "    # √Årea por habitaci√≥n\n",
    "    if 'habitaciones' in df_fe.columns:\n",
    "        df_fe['area_por_habitacion'] = df_fe['area'] / (df_fe['habitaciones'] + 1)  # +1 para evitar divisi√≥n por 0\n",
    "\n",
    "# Puntuaci√≥n de amenidades (suma de amenidades disponibles)\n",
    "if amenidades:\n",
    "    df_fe['amenidades_score'] = df_fe[amenidades].sum(axis=1)\n",
    "\n",
    "# Apartamento de lujo (m√°s de X amenidades y estrato alto)\n",
    "if 'estrato' in df_fe.columns and amenidades:\n",
    "    df_fe['es_lujo'] = ((df_fe['amenidades_score'] >= 4) & (df_fe['estrato'] >= 5)).astype(int)\n",
    "\n",
    "print(f\"\\nCaracter√≠sticas ingeniadas creadas: {len(df_fe.columns) - len(df_clean.columns)}\")\n",
    "print(f\"Total de caracter√≠sticas ahora: {len(df_fe.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Divisi√≥n de Datos\n",
    "\n",
    "Dividiremos los datos en conjuntos de entrenamiento, prueba y validaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar caracter√≠sticas para modelado\n",
    "# Para simplificar, usaremos solo caracter√≠sticas num√©ricas en esta versi√≥n b√°sica\n",
    "# En la versi√≥n completa de los scripts, se har√° encoding de categ√≥ricas\n",
    "\n",
    "# Seleccionar todas las caracter√≠sticas num√©ricas disponibles\n",
    "caracteristicas_modelo = caracteristicas_numericas + amenidades\n",
    "\n",
    "# Agregar caracter√≠sticas ingeniadas que sean num√©ricas\n",
    "if 'amenidades_score' in df_fe.columns:\n",
    "    caracteristicas_modelo.append('amenidades_score')\n",
    "if 'area_por_habitacion' in df_fe.columns:\n",
    "    caracteristicas_modelo.append('area_por_habitacion')\n",
    "if 'es_lujo' in df_fe.columns:\n",
    "    caracteristicas_modelo.append('es_lujo')\n",
    "\n",
    "# Eliminar duplicados y asegurar que existen\n",
    "caracteristicas_modelo = list(set(caracteristicas_modelo))\n",
    "caracteristicas_modelo = [c for c in caracteristicas_modelo if c in df_fe.columns]\n",
    "\n",
    "# Preparar X e y\n",
    "X = df_fe[caracteristicas_modelo].fillna(0)\n",
    "y = df_fe['precio_venta']\n",
    "\n",
    "print(f\"\\nCaracter√≠sticas para modelado: {len(caracteristicas_modelo)}\")\n",
    "print(f\"Registros totales: {len(X):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisi√≥n: 60% train, 20% test, 20% validation\n",
    "X_temp, X_val, y_temp, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=42  # 0.25 de 0.8 = 0.2 del total\n",
    ")\n",
    "\n",
    "print(\"\\nDivisi√≥n de datos:\")\n",
    "print(f\"  Train:      {len(X_train):6,} ({len(X_train)/len(X)*100:5.1f}%)\")\n",
    "print(f\"  Test:       {len(X_test):6,} ({len(X_test)/len(X)*100:5.1f}%)\")\n",
    "print(f\"  Validation: {len(X_val):6,} ({len(X_val)/len(X)*100:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Escalado de Caracter√≠sticas\n",
    "\n",
    "Normalizaremos las caracter√≠sticas para mejorar el rendimiento de algunos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalar caracter√≠sticas\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "print(\"‚úì Caracter√≠sticas escaladas\")\n",
    "print(f\"  Media de train: {X_train_scaled.mean():.6f}\")\n",
    "print(f\"  Desviaci√≥n est√°ndar de train: {X_train_scaled.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Entrenamiento de Modelos\n",
    "\n",
    "Entrenaremos m√∫ltiples modelos de regresi√≥n y compararemos su rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Regresi√≥n Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar Regresi√≥n Lineal\n",
    "print(\"Entrenando Regresi√≥n Lineal...\")\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# M√©tricas\n",
    "metricas_lr = imprimir_metricas_modelo(y_test, y_pred_lr, 'Regresi√≥n Lineal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Regresi√≥n Ridge (con regularizaci√≥n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar Ridge\n",
    "print(\"\\nEntrenando Regresi√≥n Ridge...\")\n",
    "ridge_model = Ridge(alpha=1.0, random_state=42)\n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_ridge = ridge_model.predict(X_test_scaled)\n",
    "\n",
    "# M√©tricas\n",
    "metricas_ridge = imprimir_metricas_modelo(y_test, y_pred_ridge, 'Ridge Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar Random Forest\n",
    "print(\"\\nEntrenando Random Forest...\")\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train, y_train)  # Random Forest no requiere escalado\n",
    "\n",
    "# Predicciones\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# M√©tricas\n",
    "metricas_rf = imprimir_metricas_modelo(y_test, y_pred_rf, 'Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar Gradient Boosting\n",
    "print(\"\\nEntrenando Gradient Boosting...\")\n",
    "gb_model = GradientBoostingRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42\n",
    ")\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "# M√©tricas\n",
    "metricas_gb = imprimir_metricas_modelo(y_test, y_pred_gb, 'Gradient Boosting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 XGBoost (si est√° disponible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar XGBoost si est√° disponible\n",
    "try:\n",
    "    print(\"\\nEntrenando XGBoost...\")\n",
    "    xgb_model = xgb.XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        min_child_weight=1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicciones\n",
    "    y_pred_xgb = xgb_model.predict(X_test)\n",
    "    \n",
    "    # M√©tricas\n",
    "    metricas_xgb = imprimir_metricas_modelo(y_test, y_pred_xgb, 'XGBoost')\n",
    "except NameError:\n",
    "    print(\"\\n‚ö† XGBoost no disponible, omitiendo...\")\n",
    "    metricas_xgb = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6 LightGBM (si est√° disponible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar LightGBM si est√° disponible\n",
    "try:\n",
    "    print(\"\\nEntrenando LightGBM...\")\n",
    "    lgb_model = lgb.LGBMRegressor(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        num_leaves=31,\n",
    "        min_child_samples=20,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    lgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicciones\n",
    "    y_pred_lgb = lgb_model.predict(X_test)\n",
    "    \n",
    "    # M√©tricas\n",
    "    metricas_lgb = imprimir_metricas_modelo(y_test, y_pred_lgb, 'LightGBM')\n",
    "except NameError:\n",
    "    print(\"\\n‚ö† LightGBM no disponible, omitiendo...\")\n",
    "    metricas_lgb = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comparaci√≥n de Modelos\n",
    "\n",
    "Compararemos todos los modelos entrenados para seleccionar el mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar m√©tricas de todos los modelos\n",
    "comparacion = {\n",
    "    'Modelo': [],\n",
    "    'MAE': [],\n",
    "    'RMSE': [],\n",
    "    'R¬≤': [],\n",
    "    'MAPE': []\n",
    "}\n",
    "\n",
    "modelos_metricas = [\n",
    "    ('Regresi√≥n Lineal', metricas_lr),\n",
    "    ('Ridge', metricas_ridge),\n",
    "    ('Random Forest', metricas_rf),\n",
    "    ('Gradient Boosting', metricas_gb)\n",
    "]\n",
    "\n",
    "if metricas_xgb:\n",
    "    modelos_metricas.append(('XGBoost', metricas_xgb))\n",
    "if metricas_lgb:\n",
    "    modelos_metricas.append(('LightGBM', metricas_lgb))\n",
    "\n",
    "for nombre, metricas in modelos_metricas:\n",
    "    comparacion['Modelo'].append(nombre)\n",
    "    comparacion['MAE'].append(metricas['MAE'])\n",
    "    comparacion['RMSE'].append(metricas['RMSE'])\n",
    "    comparacion['R¬≤'].append(metricas['R2'])\n",
    "    comparacion['MAPE'].append(metricas['MAPE'])\n",
    "\n",
    "df_comparacion = pd.DataFrame(comparacion)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"COMPARACI√ìN DE MODELOS\")\n",
    "print(\"=\" * 100)\n",
    "display(df_comparacion.style.highlight_max(subset=['R¬≤'], color='lightgreen')\n",
    "                              .highlight_min(subset=['MAE', 'RMSE', 'MAPE'], color='lightgreen'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar el mejor modelo basado en R¬≤\n",
    "idx_mejor = df_comparacion['R¬≤'].idxmax()\n",
    "mejor_modelo_nombre = df_comparacion.loc[idx_mejor, 'Modelo']\n",
    "mejor_r2 = df_comparacion.loc[idx_mejor, 'R¬≤']\n",
    "\n",
    "print(f\"\\nüèÜ Mejor Modelo: {mejor_modelo_nombre}\")\n",
    "print(f\"   R¬≤ Score: {mejor_r2:.4f}\")\n",
    "print(f\"   MAE: {formatear_cop(df_comparacion.loc[idx_mejor, 'MAE'])}\")\n",
    "print(f\"   RMSE: {formatear_cop(df_comparacion.loc[idx_mejor, 'RMSE'])}\")\n",
    "print(f\"   MAPE: {df_comparacion.loc[idx_mejor, 'MAPE']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualizaci√≥n de Resultados\n",
    "\n",
    "Visualizaremos el rendimiento del mejor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener predicciones del mejor modelo para visualizaci√≥n\n",
    "# (Usaremos Random Forest como ejemplo, ajustar seg√∫n el mejor modelo)\n",
    "y_pred_mejor = y_pred_rf  # Ajustar seg√∫n el mejor modelo identificado\n",
    "\n",
    "# Gr√°fico de valores reales vs predichos\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Scatter plot\n",
    "axes[0].scatter(y_test, y_pred_mejor, alpha=0.5, s=10)\n",
    "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "             'r--', lw=2, label='Predicci√≥n Perfecta')\n",
    "axes[0].set_xlabel('Precio Real (COP)', fontsize=12)\n",
    "axes[0].set_ylabel('Precio Predicho (COP)', fontsize=12)\n",
    "axes[0].set_title(f'{mejor_modelo_nombre}: Real vs Predicho', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuos\n",
    "residuos = y_test - y_pred_mejor\n",
    "axes[1].scatter(y_pred_mejor, residuos, alpha=0.5, s=10)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Precio Predicho (COP)', fontsize=12)\n",
    "axes[1].set_ylabel('Residuos (COP)', fontsize=12)\n",
    "axes[1].set_title('Gr√°fico de Residuos', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì Visualizaci√≥n generada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Evaluaci√≥n en Conjunto de Validaci√≥n\n",
    "\n",
    "Evaluaremos el mejor modelo en el conjunto de validaci√≥n (datos no vistos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones en conjunto de validaci√≥n\n",
    "# (Usaremos Random Forest como ejemplo)\n",
    "y_pred_val = rf_model.predict(X_val)\n",
    "\n",
    "# M√©tricas en validaci√≥n\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"EVALUACI√ìN EN CONJUNTO DE VALIDACI√ìN\")\n",
    "print(\"=\" * 100)\n",
    "metricas_val = imprimir_metricas_modelo(y_val, y_pred_val, f'{mejor_modelo_nombre} (Validaci√≥n)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular porcentaje de predicciones dentro del umbral de negocio (¬±20M COP)\n",
    "umbral_negocio = 20_000_000  # 20 millones COP\n",
    "errores_abs = np.abs(y_val - y_pred_val)\n",
    "dentro_umbral = (errores_abs <= umbral_negocio).sum()\n",
    "porcentaje_umbral = (dentro_umbral / len(y_val)) * 100\n",
    "\n",
    "print(f\"\\nPredicciones dentro del umbral de negocio (¬±20M COP):\")\n",
    "print(f\"  Cantidad: {dentro_umbral:,} de {len(y_val):,}\")\n",
    "print(f\"  Porcentaje: {porcentaje_umbral:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Importancia de Caracter√≠sticas (para modelos basados en √°rboles)\n",
    "\n",
    "Analizaremos qu√© caracter√≠sticas son m√°s importantes para el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de caracter√≠sticas (para Random Forest)\n",
    "importancias = pd.DataFrame({\n",
    "    'caracteristica': caracteristicas_modelo,\n",
    "    'importancia': rf_model.feature_importances_\n",
    "}).sort_values('importancia', ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 Caracter√≠sticas M√°s Importantes:\")\n",
    "print(\"=\" * 60)\n",
    "display(importancias.head(15))\n",
    "\n",
    "# Visualizaci√≥n\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_features = importancias.head(15)\n",
    "plt.barh(range(len(top_features)), top_features['importancia'])\n",
    "plt.yticks(range(len(top_features)), top_features['caracteristica'])\n",
    "plt.xlabel('Importancia', fontsize=12)\n",
    "plt.title('Top 15 Caracter√≠sticas M√°s Importantes', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Resumen y Conclusiones\n",
    "\n",
    "### Resultados Clave:\n",
    "\n",
    "1. **Modelos Evaluados**: Se entrenaron y evaluaron 4-6 modelos diferentes\n",
    "2. **Mejor Modelo**: Identificado basado en m√©tricas de test\n",
    "3. **Rendimiento en Validaci√≥n**: Verificado en datos completamente no vistos\n",
    "\n",
    "### M√©tricas de Rendimiento:\n",
    "\n",
    "- **R¬≤**: Indica qu√© tan bien el modelo explica la varianza en los precios\n",
    "- **MAE**: Error absoluto promedio en COP\n",
    "- **RMSE**: Penaliza errores grandes m√°s severamente\n",
    "- **MAPE**: Error porcentual, √∫til para comparar diferentes escalas\n",
    "\n",
    "### Hallazgos:\n",
    "\n",
    "1. **Caracter√≠sticas Importantes**:\n",
    "   - El √°rea es t√≠picamente el predictor m√°s fuerte\n",
    "   - Localidad y estrato tienen gran impacto\n",
    "   - Amenidades contribuyen al precio\n",
    "\n",
    "2. **Rendimiento del Modelo**:\n",
    "   - Los modelos de ensemble (RF, GB, XGB, LGB) generalmente superan a modelos lineales\n",
    "   - El porcentaje de predicciones dentro del umbral de negocio es cr√≠tico para HabitAlpes\n",
    "\n",
    "### Pr√≥ximos Pasos:\n",
    "\n",
    "1. **Interpretabilidad**: An√°lisis SHAP y LIME para explicar predicciones individuales\n",
    "2. **Valor de Negocio**: Calcular ROI y punto de equilibrio\n",
    "3. **Recomendaciones**: Insights accionables para HabitAlpes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusi√≥n del Modelado\n",
    "\n",
    "Este notebook ha cubierto:\n",
    "\n",
    "‚úÖ **Preprocesamiento completo de datos**\n",
    "\n",
    "‚úÖ **Ingenier√≠a de caracter√≠sticas efectiva**\n",
    "\n",
    "‚úÖ **Entrenamiento de m√∫ltiples modelos de ML**\n",
    "\n",
    "‚úÖ **Evaluaci√≥n exhaustiva con m√∫ltiples m√©tricas**\n",
    "\n",
    "‚úÖ **Selecci√≥n del mejor modelo basado en rendimiento**\n",
    "\n",
    "El siguiente notebook se enfocar√° en la interpretabilidad del modelo usando SHAP y LIME para entender las decisiones del modelo y proporcionar transparencia a HabitAlpes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
